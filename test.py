import torch.nn as nn
import torch
from datetime import datetime, timedelta

# an Embedding module containing 10 tensors of size 3

def norm(input,mask):
        lens=mask.sum(-1)
        for i in range(input.size(0)):
            w=input[i][:lens[i],:lens[i]].view(lens[i], lens[i])#3x3
            #w=input[i][mazzsk[i].unsqueeze(-1) & mask[i].unsqueeze(-2)].view(lens[i], -1)
            #gamma = torch.ones(w.size(-1))
            #beta = torch.zeros(w.size(-1))
            eps = 1e-6
            #mean = w/lens[i]#3x2
            mean = w.mean(-1, keepdim=True)
            #std=

            std = w.std(-1, unbiased=False, keepdim=True)
            
            w.sub_(mean)
            w.div_(std+eps)
            #w=(w - mean) / (std + eps)
            #w = nn.Softmax(-1)(w)
            #input[i, 0:w.size(0), 0:w.size(1)].copy_(w)
##print(torch.finfo().tiny)

def my_norm(input,mask):
        lens=mask.sum(-1)
        for i in range(input.size(0)):
            w=input[i][:lens[i],:lens[i]].view(lens[i], lens[i])#3x3
            #w=input[i][mazzsk[i].unsqueeze(-1) & mask[i].unsqueeze(-2)].view(lens[i], -1)
            #gamma = torch.ones(w.size(-1))
            #beta = torch.zeros(w.size(-1))
            eps = 1e-6
            #mean = w/lens[i]#3x2
            mean=(w.sum(-1)/lens[i]).unsqueeze(-1)

            std=torch.sqrt(torch.pow(w-mean,2).sum(-1)/lens[i]).unsqueeze(-1)
            #std = w.std(-1, unbiased=False, keepdim=True)
            
            w.sub_(mean)
            w.div_(std+eps)
            #w=(w - mean) / (std + eps)
            #w = nn.Softmax(-1)(w)
            #input[i, 0:w.size(0), 0:w.size(1)].copy_(w)

def my_norm1(input,mask):
    lens=mask.sum(-1).unsqueeze(-1)#(3,2) 2    #lens=mask.sum(-1).unsqueeze(-1).unsqueeze(-1)
    
    t=mask.unsqueeze(-1)&mask.unsqueeze(-2)
    
    input.masked_fill_(~t,0)#2x3x3
    
    mean=(input.sum(-1)/lens).unsqueeze(-1)#2x3矩阵。->2x3x1
    
    std=torch.sqrt(torch.pow(input-mean,2).masked_fill_(~t,0).sum(-1)/lens).unsqueeze(-1)#2x3 ->2x3x1
    
    return ((input-mean)/(std+1e-6)).masked_fill_(~t,float('-inf'))

def Scale(input,mask):
    lens=mask.sum(-1).unsqueeze(-1)#(3,2) 2    #lens=mask.sum(-1).unsqueeze(-1).unsqueeze(-1)
    





#测试上面的代码
'''
lens=torch.ones(5,4)
n_out=3
w=torch.Tensor([])
embed = w.new_zeros(*lens.shape, n_out)

print(*lens.shape)
print(embed)
'''

input=torch.tensor([[[ 3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -9.1715e-03,
           9.1715e-03, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.0000e+00,  1.0000e+00,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -2.7286e-09,  2.7286e-09, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -5.5196e-23,  5.5196e-23, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37]]], device='cuda:5', dtype=torch.double)
#input.requires_grad_()

#print(30*torch.finfo().tiny)


input[0][5].fill_(-torch.finfo().tiny)
input[0][5][5]=(31*torch.finfo().tiny)

input[0][9].fill_(-torch.finfo().tiny)
input[0][9][9]=(31*torch.finfo().tiny)

input[0][13].fill_(-torch.finfo().tiny)
input[0][13][13]=(31*torch.finfo().tiny)

input[0][17].fill_(-torch.finfo().tiny)
input[0][17][17]=(31*torch.finfo().tiny)


#print(input[:,1:,1:].det())
#print(input[:,1:,1:].slogdet())



loss2=input[:,1:,1:].abs_()
#print(loss2)

'''
print(loss2.size())

print(loss2[0][16])
diag=loss2[0][16][16]
sum=loss2[0][16].sum()-diag

print(diag)
print(sum)
print(diag-sum)
'''

'''
for i in range(loss2.size(1)):
    diag=loss2[0][i][i]
    sum=loss2[0][i].sum()-diag
    print(i,end='\t')
    print(diag-sum)
'''




'''
q=torch.tensor([[[3.5265e-38, 1.1755e-38, 1.1755e-38, 1.1755e-38],
         [1.1755e-38, 3.5265e-38, 1.1755e-38, 1.1755e-38],
         [1.1755e-38, 1.1755e-38, 3.5265e-38, 1.1755e-38],
         [1.1755e-38, 1.1755e-38, 1.1755e-38, 1]]])
q.requires_grad_()
loss=q[:,1:,1:].slogdet()[1]
print(loss)


loss.backward()

print(q.grad)
'''


#print(q)





'''
logZ=torch.tensor([[[ 3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -4.0384e-35, -4.9236e-21, -3.4805e-24, -1.1563e-09,
           1.0009e+00, -3.8815e-09, -6.9141e-17, -1.0000e+00, -1.1822e-21,
          -1.9620e-15, -4.5865e-22, -9.1116e-04, -5.1636e-19, -1.7285e-16,
          -6.1704e-29, -1.1656e-10, -1.0511e-22, -7.5689e-35, -2.0506e-37,
          -9.3585e-24, -5.4691e-33, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -4.0114e-28, -6.3549e-32, -6.6883e-17,
          -1.1755e-38, -3.3851e-16, -2.6808e-23, -1.2607e-07,  1.2660e-07,
          -1.0532e-21, -1.1482e-27, -5.2890e-10, -3.0531e-31, -3.4853e-22,
          -1.2697e-33, -6.5447e-16, -6.8827e-34, -1.1755e-38, -1.1755e-38,
          -1.2686e-27, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -4.3875e-35, -1.1755e-38, -4.9651e-24,
          -1.1755e-38, -3.6634e-23, -1.2823e-29, -1.8848e-14, -1.1755e-38,
          -6.7075e-28, -3.3578e-33, -3.4400e-16,  1.9192e-14, -7.8933e-28,
          -2.8616e-38, -3.8278e-21, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.6308e-31, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -5.4676e-35,
          -1.1755e-38, -5.7834e-34, -1.1755e-38, -3.1598e-25, -1.1755e-38,
          -1.1030e-37, -1.1755e-38, -3.6317e-26, -1.1755e-38, -5.9130e-37,
          -1.1755e-38, -6.9586e-30,  3.5230e-25, -1.1755e-38, -1.1755e-38,
          -1.8603e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37, -1.1755e-38,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,  3.5265e-37,
          -1.1755e-38],
         [-1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
          -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38, -1.1755e-38,
           3.5265e-37]]],dtype=torch.float64)
           #device='cuda:5'
logZ.requires_grad_()

#loss=logZ.slogdet()[1]
#loss.backward()

print(logZ.slogdet()[1])
print(logZ.det())

'''


#print(logZ.logdet())
#print(logZ.slogdet())

'''
w=torch.ones(2,3,3).float()
print(w.det())
print(w.logdet())
print(w.slogdet())
'''
'''
logZ.requires_grad_()
loss1=logZ[:,1:,1:].slogdet()[1]

print(loss1)

#loss=loss1-loss2

loss1.backward()

'''
#print(input.grad)

'''
norm(s,mask)
print(s)


q=torch.arange(2*3*3).float().view(2,3,3)

my_norm(q,mask)
print(q)
z=torch.arange(2*3*3).float().view(2,3,3)

w=my_norm1(z,mask)
print(w)
'''
x = torch.ones(2,2,2)
x.requires_grad_()

out = x.pow(2)
out =out.pow(2)
print(out)
print(out.is_leaf)
mask=torch.Tensor([[False,False],
                    [True,True]]).bool()
out1=out[0][mask].sum()
out2=out[0][mask].sum()
loss=out1+out2
loss.backward()
print(x.grad)




'''
scores=torch.arange(2*3*3).view(2,3,3).float()
print(scores)
mask=torch.Tensor([[True,True,True],
                  [True,True,False]]).bool()
mask[:,0]=False
random_mask=torch.ones(2).bernoulli_(1).ne(0)
target=torch.Tensor([[0,1,2],
                     [0,2,1]]).long()
w=scores.gather(-1, target.unsqueeze(-1))
q=scores.gather(-1, target.unsqueeze(-1)).squeeze(-1)
u=scores.gather(-1, target.unsqueeze(-1)).squeeze(-1)[mask&random_mask.unsqueeze(-1)]


score = scores.gather(-1, target.unsqueeze(-1)).squeeze(-1)[mask&random_mask.unsqueeze(-1)].sum()
print(score)

'''
#验证一个batch做norm的代码、
'''
input=torch.ones(2*3*3).view(2,3,3).float()
print(input)
mask=torch.Tensor([[True,True,True],
                  [True,True,False]]).bool()
lens=mask.sum(-1).unsqueeze(-1)#(3,2) 2    #lens=mask.sum(-1).unsqueeze(-1).unsqueeze(-1)
t=mask.unsqueeze(-1)&mask.unsqueeze(-2)
input.masked_fill_(~t,0)#2x3x3

mean=(input.sum(-1)/lens).unsqueeze(-1)#2x3矩阵。->2x3x1
print(mean)
std=torch.sqrt(torch.pow(input-mean,2).masked_fill_(~t,0).sum(-1)/lens).unsqueeze(-1)#2x3 ->2x3x1
print(std)
w=(input-mean)/(std+1e-6)
w.masked_fill_(~t,float('-inf'))
print(w)
'''

#print(torch.pow(input-mean,2).sum(-1))


#print(input.sum(-1)/lens)#2x3矩阵。


#mean=(input.sum(-1)/lens).unsqueeze(-1)#2x3

#print(mean)


#print(l-mean)

'''


#std:求出来也是个2x3的矩阵。
#print(torch.pow(l-mean,2))



#print(l.sum(-1))

'''
#std=torch.sqrt(torch.pow(l-mean,2).sum())/l.sum())

#print(std)





'''
z=torch.arange(3).float()   

s=z.mean()
print(s)
print(torch.pow(z-s,2))

std=torch.sqrt(torch.pow(z-s,2).sum()/z.sum())
print(std)

print(z.std(False))
'''


'''
print(lens)

print(mask.unsqueeze(-1)&mask.unsqueeze(-2))

t=mask.unsqueeze(-1)&mask.unsqueeze(-2)
l=input.masked_fill_(~t,0)
#l=input.masked_scatter_(~t,0)

l=l[mask]
print(l)
print(input)

mean=input/lens

print(mean)

'''
#print(input)

'''
norm(input,mask)

print(input)

'''

'''
x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)

w=x[0,:]

print(w._version)
z=w.std(-1, unbiased=True, keepdim=True)
w.add_(1)
print(w._version)
print(dd_x._version)
print(x[0,:]._version)
'''

'''
out = x.pow(2)

w=out[0,:]
w.add_(1)

print(out)

out =out.pow(2)

print(out)
print(out.is_leaf)
out=out.sum()
print(out)
out.backward()	
print(x.grad)
'''

'''
s_arc=torch.ones(4,4,4)

mask=torch.Tensor([ [True,True,True,False],
                    [True,True,False,False],
                    [True,True,False,False],
                    [True,True,True,False]]).bool()

s_arc.masked_fill_(~mask.unsqueeze(1), float('-inf'))#把列pad的地方补为-inf，为了不让计算loss的时候带入，而行，因为mask的出现并不会出现。


print(s_arc)
'''

'''
mask_[:,0]=0
w=mask_.unsqueeze(-1) & mask_.unsqueeze(-2)
w.index_fill_(2,score.new_tensor(0).long(),1)
print(w)

score = score.masked_fill(~w,float('-inf'))

#score = score.masked_fill(~(mask_.unsqueeze(-1) & mask_.unsqueeze(-2)), float('-inf'))#(为了把填充的部分的分数抹掉)

print(score)
'''

'''
t=mask_.unsqueeze(1)
u=mask_.unsqueeze(-1)
(mask_.unsqueeze(1) & mask_.unsqueeze(-1))#生成一个批次的句子。
print((mask_.unsqueeze(1) & mask_.unsqueeze(-1)))
'''
#print((mask_.unsqueeze(-1) & mask_.unsqueeze(-2)))


#print(torch.masked_fill(score,~(mask_.unsqueeze(1) & mask_.unsqueeze(-1)),-float('-inf')))

#print(torch.masked_fill(score,~mask_.unsqueeze(1),-float('-inf')))

'''
b = torch.Tensor([[[1,1],
                    [2,2]],

                    [[3,3],
                    [4,4]]])
mask=torch.Tensor([ [False,True],
                    [False,True]]).bool()

#mask[:,0]=False
print(b[mask])



w=torch.Tensor([ [2,2],
                    [1,1]])

print(w+b)

c=torch.Tensor([True,False]).bool()

print(c.size())
print(w[c])

q=torch.Tensor([[True,False],
                [True,False]]).bool()

print(w[q])

print(w+torch.Tensor([(1,2)]))
'''

'''
c=torch.tensor([1,2,3])
#print(b-c)

print(b)

print(b-c.view(-1,1))
'''







